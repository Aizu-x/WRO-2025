# ğŸ¤– Autonomous Robot for WRO 2025 - Future Engineers

Welcome to the official repository for our **Autonomous Robot** project, built as part of our entry for the **WRO 2025 Future Engineers Competition**. This project showcases a self-driving robot capable of detecting colored zones, avoiding collisions, and intelligently navigating its environment â€” all under the constraints of time, resources, and technical challenges.

## ğŸ Project Overview

Our robot was designed to operate autonomously in a structured environment with the following capabilities:

- **Obstacle Detection** using real-time vision and ultrasonic sensing.
- **Color Zone Recognition**:
  - ğŸ”´ **Red** â€“ Obstacle zone
  - ğŸŸ¢ **Green** â€“ Obstacle zone
  - ğŸ…¿ï¸ **Pink** â€“ Parking area
- **Collision Avoidance** with **two ultrasonic sensors**, enabling the robot to detect nearby objects and avoid crashes during navigation.

This repository contains all the core code used in the competition.

## âš™ï¸ Technologies & Components

### ğŸ§© Hardware:
- Microcontroller (e.g., Raspberry Pi 4 Model B)
- 2x Ultrasonic Sensors (for distance measurement and obstacle avoidance)
- IMX500 AI Camera (for color-based zone detection)
- Motor Driver & Chassis
- Power Supply (Battery Pack)

### ğŸ’» Software:
- Python (primary language)
- OpenCV (for color detection and image processing)
- YOLO
- Sensor libraries for real-time data handling

## ğŸ› ï¸ How It Works

- **Color Detection**: The camera continuously scans the environment and uses HSV thresholds to identify red, green, and pink zones including trained data that contains thousands of pictures.
- **Ultrasonic Sensors**: Positioned both in the front sides to provide obstacle distance readings in real-time.
- **Decision-Making Logic**: Combines input from sensors and camera to make real-time navigation decisions (e.g., stop, turn, park).



